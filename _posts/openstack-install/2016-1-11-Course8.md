---
layout: post
title: Course 8 Configuring Ansible and running playbooks
categories: openstack-install
author: April 8th, 2016  by Xin Zhang
description: Course content snapshot should be placed here. OpenStack began in 2010 as a joint project of Rackspace Hosting and NASA.
---

***
#### Course 8: Configuring Ansible and running playbooks #

* * *

Configuring Ansible

To configure our containers to be able to talk to the outside world as well as each other, you will need to edit the file openstack_user_config.yml found in the directory: /etc/open-stack_deploy/ . The beginning of the file has a section titled cidr_networks.

For each of the subsections (container, tunnel, and storage) you will need to assign a non-private IP range. In this example 10.20.20.0/24 is used for the container network (which is the same as the management network), 10.20.30.0/24 is used for the tunnel network (which is the vxlan network), and 10.20.40.0/24 is used for the storage network.

The next section is title used_ips. This section tells Ansible what IP ranges are currently in use and not to use them. That section should be replaced with the following:

```sh
10.20.20.2,10.20.20.50
10.20.30.2,10.20.30.50
10.20.40.2,10.20.40.50
```

The step above provides a range of IPs from 2-50 so that there is room for expansion. However, this set range does not necessarily need to be this large.

* * *

END OF VIDEOS

* * *

The next section is titled **global_overrides**, which will allow you to replace the subsections **internal_lb_vip_address** with the example internal address of **10.20.20.10** and then replace **external_lb_vip_address** with **10.241.1.59**. The internal IP address used in the example was arbitrarily chosen from the range for the applicable mgmt network, while the external address is the address for the HAProxy/Logging node. The two subsections that follow are only to be changed if they are different than what is configured in the hosts (**tunneling_bridge, management_bridge**).

The next section to be modified allows for the configuration of a VLAN for a physical provider network. The first subsection describes VLAN as having **type:"flat"** and **net_name: "flat"**. Do not edit that section and proceed with the following to setup a VLAN for a physical provider network. Take the entire section beginning with the subheading **-network** and delete everything including the subsection **-linux_bridge_agent**.

The next section that will need to be modified is titled shared infra hosts. You will need to modify the following section so that it reads as follows:

  
  
  
  

```sh
shared-infra_hosts:
```

**&lt;begin delete&gt;**

```sh
    aiol:
        #rabbitmq, and galera are set to multiples to test clustering
        affinity:
        galera_container: 3
        rabbit_mq_container: 3
        ip: 172.29.236.100
```

**&lt;end delete&gt;**

In the case of the example given above, you would replace the above deleted section with the following:

```sh
    infra1:
        ip: 10.20.20.55
        infra2:
        ip: 10.20.20.56
        infra3:
        ip: 10.20.20.67
```

Using the example above, you would replace the next deleted section with the following:

```sh
    infra1:
      ip: 10.20.20.55
    infra2:
      ip: 10.20.20.56
    infra3:
      ip: 10.20.20.67
```

```sh
os-infra_hosts:
```

**&lt;begin delete&gt;**

```sh
        aiol:
      # Horizon is set to multiple to test clustering. This test only requires x2.
      affinity:
         horizon_containter: 2
      ip: 172.29.236.100
```

**&lt;end delete&gt;**


Repeat the same operation for **storage-infra_hosts**, **repo-infra_hosts**, **identity_hosts**, and **network_hosts**. Delete the body of the section and replace it with the infra1, infra2, and infra3 ips as was demonstrated above.

Next, the compute hosts are different. Compute host IPs are the same as your previously assigned compute hosts. Using the example case, you would delete the body as shown above, but replace it with the single compute host IP: **10.241.1.58**.

The last sections that need to be edited are **log_hosts** and **haproxy_hosts**. You will need to delete their respective bodies as discussed previously; and, since the HAProxy node is on the same server as the Logging node, you will need to edit both to contain the following:

```sh
haproxy_log:
         ip: 10.241.1.59
```

This concludes the editing of this file. Save and quit. Ansible now has been informed as to where everything is to reside. Next, you will need to use a python script to auto-fill the file **user_secrets.yml** with the passwords required for the various service credentials.

* * *

#### Autofilling user_secrets #

First, navigate to the directory **/opt/openstack-ansible/scripts** and run the python script that will generate the passwords needed by the following command:

```sh
$ python pw_token_gen.py --file /etc/openstack_deploy/user_secrets.yml
```
Then, verify that **user_secrets.yml** has been modified by opening it with the editor of your choice. You can also modify the line **keystone_auth_admin_password** to contain the password **openstack**. This can be used to avoid having to type in the otherwise long string that is automatically generated by the python script every time it will be needed later. You can always create a much more complex password if needed.

* * *

#### Final Ansible configuration and syntax check #

Next, check the file **user_variables** located in the directory **/etc/openstack_deploy/** to make sure that the line for **nova_virt_type: kvm** is commented out as follows:

```sh
# nova_virt_type: kvm
```

Then, check the integrity of your configuration files by navigating to the directory **$ cd /opt/openstack-ansible/playbooks** and using the following script: **openstack-ansible setup-everything.yml --syntax-check**

You may run into a small problem when you first start running your playbooks if Ansible is having a problem running sysstat. To correct this, ansible.cfgmay have to be modified by adding the following line to the end of the file:

**scp_if_ssh = True**

* * *

Playbooks

  

Finally, you can start running playbooks. The playbooks may fail or have a warning about ignored problems. Usually, if you simply rerun the playbook(s) that had a problem, it/they will finish installing correctly. From the same **/opt/openstack-ansible/playbooks** directory you can run the playbooks in this order:

  

```sh
$ setup-hosts.yml
```
```sh
$ setup-infra.yml
```
```sh
$ setup-openstack.yml
```

  

If your install hangs on lxc you can manually restart it by using the following commands:

```sh
$ setup-haproxy.yml
$ setup-infrastructure.yml
$ memcached-install.yml
```

Next, list the containers to verify that they were created properly:

```sh
$ lxc-ls -f
```

Then, connect to the containers:

```sh
$ lxc-attach -n infra1_neutron_agents_container-1564d34 # (The last contiguous variable is a container listed after Ansible creates containers for you. So, the number at the end will probably be different for each creation)
```

Once all the playbooks have been run successfully and/or containers successfully deployed, you can use Horizon to open your cloud and spin up VM's...